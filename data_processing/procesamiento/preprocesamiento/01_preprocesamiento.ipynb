{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3abcb90f",
   "metadata": {},
   "source": [
    "# **PREPROCESAMIENTO DE TEXTOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abc8abd",
   "metadata": {},
   "source": [
    "## **PARA EMBEDDINGS NO CONTEXTUALES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53026964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "\n",
    "df = pd.read_csv(\"datas/datasetClean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccff16e",
   "metadata": {},
   "source": [
    "Lo primero es limpiar símbolos y distintas cosas que el modelo pueda malinterpretar. Observando los textos de los articulos, hemos detectado que se cuelan algunos simbolos como \">\" \"<\" o comillas,...Hemos tomado la decisión de eliminarlas para un mejor funcionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "114d233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\", \"textcat\"])\n",
    "tqdm.pandas()\n",
    "\n",
    "STOPWORDS = set(nlp.Defaults.stop_words)\n",
    "PLACEHOLDER_RE = re.compile(r\"__\\w+__\")\n",
    "\n",
    "URL_RE = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "HTML_TAG_RE = re.compile(r\"<[^>]+>\")\n",
    "BOILERPLATE_RE = re.compile(\n",
    "    r\"(^read more:.*$|^story continues.*$|copyright\\s*©.*$)\",\n",
    "    flags=re.IGNORECASE | re.MULTILINE,\n",
    ")\n",
    "CASHTAG_RE = re.compile(r\"\\$([A-Za-z]{1,10})\\b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "489d248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_rules(text: str) -> str:\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\"\n",
    "    text = (text.replace(\"’\", \"'\").replace(\"“\", '\"').replace(\"”\", '\"')\n",
    "                 .replace(\"–\", \"-\").replace(\"—\", \"-\")).lower()\n",
    "    t = BOILERPLATE_RE.sub(\"\", text)\n",
    "    t = HTML_TAG_RE.sub(\" \", t)\n",
    "    t = URL_RE.sub(\" \", t)\n",
    "    t = re.sub(CASHTAG_RE, \"__TICKER__\", t)\n",
    "\n",
    "    # placeholders financieros\n",
    "    t = re.sub(r'\\bQ([1-4])\\b', r'__QTR\\1__', t, flags=re.IGNORECASE)\n",
    "    t = re.sub(r'\\b[+-]?\\d[\\d,\\.]*\\s*%(?=\\W|$)', '__PERCENT__', t)\n",
    "    t = re.sub(r'\\b[+-]?\\d[\\d,\\.]*\\s*percent(?=\\W|$)', '__PERCENT__', t, flags=re.IGNORECASE)\n",
    "    t = re.sub(r'\\b[+-]?\\d[\\d,\\.]*\\s*per\\s+cent(?=\\W|$)', '__PERCENT__', t, flags=re.IGNORECASE)\n",
    "    t = re.sub(r'(\\$|€|£)\\s*\\d[\\d,\\.]*\\s*(?:bn|b|m|k)?\\b', '__MONEY__', t, flags=re.IGNORECASE)\n",
    "    t = re.sub(r'\\b\\d[\\d,\\.]*\\s*(million|billion|trillion|bn|m)\\b', '__AMOUNT__', t, flags=re.IGNORECASE)\n",
    "    t = re.sub(r'\\b(19|20)\\d{2}\\b', '__YEAR__', t)\n",
    "    t = re.sub(r'\\b((jan|feb|mar|apr|may|jun|jul|aug|sep|sept|oct|nov|dec)[a-z]*\\s+\\d{1,2})\\b',\n",
    "               '__DATE__', t, flags=re.IGNORECASE)\n",
    "    t = re.sub(r'\\b(\\d{1,2}\\s+(jan|feb|mar|apr|may|jun|jul|aug|sep|sept|oct|nov|dec)[a-z]*)\\b',\n",
    "               '__DATE__', t, flags=re.IGNORECASE)\n",
    "    # números genéricos al final\n",
    "    t = re.sub(r'(?<![A-Za-z_])\\b\\d[\\d,\\.]*\\b(?![A-Za-z_])', '__NUM__', t)\n",
    "    t = re.sub(r'\\s+', ' ', t).strip()\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4267e615",
   "metadata": {},
   "source": [
    "### Problema que nos ha surgido: \n",
    "\n",
    "Acronimos, bolsas como el S&P,...Se eliminaban de los textos porque teniamos mal hecho un filtro al lemmatizar. Para esto hemos tratado de resolver introducioendo una variable KEEP_TERMS con terminos relevanates que hemos visto por las noticias, así como ACRONYM_RE para casos como COS o los que no hayamos metido en la lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87e9202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "STOPWORDS.discard(\"us\")  # mantener \"US\" como país\n",
    "\n",
    "KEEP_TERMS = {\n",
    "    \"uk\", \"us\", \"eu\", \"ai\", \"ceo\", \"cfo\", \"ipo\", \"esg\", \"gdp\", \"cpi\", \"pmi\", \"ppi\",\n",
    "    \"eps\", \"roi\", \"ebitda\", \"fx\", \"irr\", \"yoy\", \"qoq\", \"bps\", \"ev\", \"iot\", \"ml\",\n",
    "    \"nyse\", \"nasdaq\", \"dow\", \"sp500\", \"ftse\", \"dax\", \"cac\", \"nikkei\", \"tsx\",\n",
    "    \"hk\", \"jp\", \"cn\", \"in\", \"br\", \"mx\", \"de\", \"fr\", \"it\", \"sg\", \"za\", \"kr\",\n",
    "    \"gm\", \"ge\", \"bp\", \"ibm\", \"aapl\", \"tsla\", \"msft\", \"meta\", \"googl\",\n",
    "    \"ons\", \"imf\", \"oecd\", \"ecb\", \"boe\", \"fed\", \"sec\", \"bis\", \"opec\", \"wto\", \"un\"\n",
    "}\n",
    "\n",
    "ACRONYM_RE = re.compile(r\"^[A-Z]{2,5}$\")       # UK, ONS, GDP\n",
    "MIXED_CASE_RE = re.compile(r\"^[A-Z0-9&]{2,6}$\")  # 5G, S&P, AT&T\n",
    "\n",
    "def spacy_clean_strong(doc) -> str:\n",
    "    out = []\n",
    "    for tok in doc:\n",
    "        text_tok = tok.text\n",
    "        lemma = tok.lemma_.lower()\n",
    "\n",
    "        # --- Placeholders (ej: __MONEY__) ---\n",
    "        if text_tok.startswith(\"__\") and text_tok.endswith(\"__\"):\n",
    "            out.append(text_tok)\n",
    "            continue\n",
    "\n",
    "        # --- Espacios o puntuación ---\n",
    "        if tok.is_punct or tok.is_space:\n",
    "            continue\n",
    "\n",
    "        # --- Stopwords primero ---\n",
    "        if lemma in STOPWORDS:\n",
    "            continue\n",
    "\n",
    "        # --- Siglas importantes ---\n",
    "        if lemma in KEEP_TERMS:\n",
    "            out.append(lemma)\n",
    "            continue\n",
    "\n",
    "        # --- Detectar acrónimos por patrón ---\n",
    "        if ACRONYM_RE.match(text_tok) or MIXED_CASE_RE.match(text_tok):\n",
    "            out.append(text_tok.lower())\n",
    "            continue\n",
    "\n",
    "        # --- Palabras normales ---\n",
    "        if lemma.isalpha() and len(lemma) >= 3:\n",
    "            out.append(lemma)\n",
    "\n",
    "    return \" \".join(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d978a798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5160/5160 [02:02<00:00, 42.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: datas/processData.csv\n"
     ]
    }
   ],
   "source": [
    "base_col = \"article_text\"\n",
    "assert base_col in df.columns, f\"No existe la columna {base_col}\"\n",
    "\n",
    "df[\"text_nc_step1\"] = df[base_col].apply(pre_rules)\n",
    "df[\"text_nc\"] = df[\"text_nc_step1\"].progress_apply(lambda x: spacy_clean_strong(nlp(x)))\n",
    "\n",
    "columnasNecesarias = [\"article_text\",\"text_nc_step1\", \"text_nc\", ]\n",
    "out_path = \"datas/processData.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "print(\"Guardado:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e98ec6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================\n",
      "Texto original\n",
      "============================\n",
      "\n",
      "The UK jobs market continues to show signs of weakness, with pay growth slowing and unemployment edging higher ahead of the autumn budget next month.\n",
      "The latest data from the Office for National Statistics (ONS), released on Tuesday, showed that annual wage growth excluding bonuses in the three months to August was 4.7%, down slightly from 4.8% between May and July.\n",
      "The unemployment rate came in at 4.8% for the period, slightly higher than the 4.7% recorded for the previous three months.\n",
      "The number of employees on the payroll in the year to August was estimated to have fallen by 93,000, though it increased by 10,000 between July and August.\n",
      "Early estimates for the number of payrolled employees in September suggested a fall of 100,000 on the year and 10,000 on a monthly basis, though the ONS said this was likely to be revised when more data is received next month.\n",
      "The estimated number of job vacancies fell by 9,000 from the previous three months to 717,000 in July to September.\n",
      "Re ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OUT_COL = \"text_nc\"\n",
    "\n",
    "\n",
    "# Creamos una máscara para verificar que hay textos no vacíos\n",
    "mask_valid = df[OUT_COL].notna() & (df[OUT_COL].str.len() > 0)\n",
    "\n",
    "\n",
    "first_original_text = df.loc[mask_valid, \"article_text\"].iloc[0]\n",
    "first_preprocessed_text = df.loc[mask_valid, OUT_COL].iloc[0]\n",
    "first_half_proc_text = df.loc[mask_valid,\"text_nc_step1\"].iloc[0]\n",
    "\n",
    "print(\"\\n============================\") \n",
    "print(\"Texto original\") \n",
    "print(\"============================\\n\")\n",
    "print(first_original_text[:1000], \"...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4ef56f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================\n",
      "Texto preprocesado con etiquetas\n",
      "============================\n",
      "\n",
      "the uk jobs market continues to show signs of weakness, with pay growth slowing and unemployment edging higher ahead of the autumn budget next month. the latest data from the office for national statistics (ons), released on tuesday, showed that annual wage growth excluding bonuses in the three months to august was __PERCENT__, down slightly from __PERCENT__ between may and july. the unemployment rate came in at __PERCENT__ for the period, slightly higher than the __PERCENT__ recorded for the previous three months. the number of employees on the payroll in the year to august was estimated to have fallen by __NUM__, though it increased by __NUM__ between july and august. early estimates for the number of payrolled employees in september suggested a fall of __NUM__ on the year and __NUM__ on a monthly basis, though the ons said this was likely to be revised when more data is received next month. the estimated number of job vacancies fell by __NUM__ from the previous three months to __NUM__ in july to september. liz mckeown, director of economic statistics at the ons, said: \"after a long period of weak hiring activity, there are signs that the falls we have seen in both payroll numbers and vacancies are now levelling off. \"we see different patterns across the age ranges with record numbers of over-65s in work, while the increase in unemployment was driven mostly by younger people.\" the figures come ahead of the government's autumn budget, which chancellor rachel reeves is due to deliver on __DATE__, with speculation ramping up as to what policy changes she could announce to raise funds to support public finances. professor joe nellis, an economic adviser at accountancy and advisory firm mha, said that the labour market \"continues to show signs of strain\". \"hiring momentum has slowed across most sectors, with many employers holding off on new recruitment or scaling back hours instead of making redundancies,\" he said. \"while this suggests a degree of resilience, it also signals that businesses are operating with caution amid fragile demand, elevated borrowing costs, and uncertainty ahead of the autumn budget.\" ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n============================\") \n",
    "print(\"Texto preprocesado con etiquetas\") \n",
    "print(\"============================\\n\")\n",
    "print(first_half_proc_text, \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "647e6fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================\n",
      "Texto preprocesado\n",
      "============================\n",
      "\n",
      "uk job market continue sign weakness pay growth slowing unemployment edge higher ahead autumn budget month late datum office national statistic ons release tuesday annual wage growth exclude bonus month august percent slightly percent july unemployment rate come percent period slightly high percent record previous month number employee payroll year august estimate fall num increase num july august early estimate number payrolle employee september suggest fall num year num monthly basis likely revise datum receive month estimate number job vacancy fall num previous month num july september liz mckeown director economic statistic ons long period weak hire activity sign fall payroll number vacancy level different pattern age range record number work increase unemployment drive young people figure come ahead government autumn budget chancellor rachel reeves deliver date speculation ramp policy change announce raise fund support public finance professor joe nellis economic adviser accountancy advisory firm mha labour market continue sign strain hire momentum slow sector employer hold new recruitment scale hour instead redundancy suggest degree resilience signal business operate caution amid fragile demand elevated borrowing cost uncertainty ahead autumn budget ...\n",
      "\n",
      "Número de tokens analizados: 431\n",
      "\n",
      "Primeros 30 tokens:\n",
      "\n",
      "[('The', 'DET', 'the'), ('UK', 'PROPN', 'UK'), ('jobs', 'NOUN', 'job'), ('market', 'NOUN', 'market'), ('continues', 'VERB', 'continue'), ('to', 'PART', 'to'), ('show', 'VERB', 'show'), ('signs', 'NOUN', 'sign'), ('of', 'ADP', 'of'), ('weakness', 'NOUN', 'weakness'), (',', 'PUNCT', ','), ('with', 'ADP', 'with'), ('pay', 'NOUN', 'pay'), ('growth', 'NOUN', 'growth'), ('slowing', 'NOUN', 'slowing'), ('and', 'CCONJ', 'and'), ('unemployment', 'NOUN', 'unemployment'), ('edging', 'VERB', 'edge'), ('higher', 'ADV', 'higher'), ('ahead', 'ADV', 'ahead'), ('of', 'ADP', 'of'), ('the', 'DET', 'the'), ('autumn', 'NOUN', 'autumn'), ('budget', 'NOUN', 'budget'), ('next', 'ADJ', 'next'), ('month', 'NOUN', 'month'), ('.', 'PUNCT', '.'), ('\\r\\n', 'SPACE', '\\r\\n'), ('The', 'DET', 'the'), ('latest', 'ADJ', 'late')]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n============================\") \n",
    "print(\"Texto preprocesado\") \n",
    "print(\"============================\\n\")\n",
    "print(first_preprocessed_text, \"...\\n\")\n",
    "\n",
    "    # Tokenización de verificación con spaCy\n",
    "doc_test = nlp(first_original_text)\n",
    "verification_data = [(w.text, w.pos_, w.lemma_) for w in doc_test]\n",
    "\n",
    "print(f\"Número de tokens analizados: {len(verification_data)}\\n\")\n",
    "print(\"Primeros 30 tokens:\\n\")\n",
    "print(verification_data[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b52312a",
   "metadata": {},
   "source": [
    "## **PARA EMBEDDINGS CONTEXTUALES**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
